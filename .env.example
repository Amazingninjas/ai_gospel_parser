# AI Gospel Parser Configuration
# Copy this file to .env and configure your preferred AI provider

# ============================================================================
# AI PROVIDER SELECTION
# ============================================================================
# Choose: "ollama" (local/private) or "gemini" (cloud API)
AI_PROVIDER=ollama

# ============================================================================
# OLLAMA CONFIGURATION (Local AI - Free, Private)
# ============================================================================
# Ollama server URL (default: http://localhost:11434)
# WSL users: Use Windows host IP (check with: ip route | grep default)
OLLAMA_HOST=http://localhost:11434

# Model name (default: mixtral)
# Other options: llama2, mistral, phi3:mini
OLLAMA_MODEL=mixtral

# ============================================================================
# GOOGLE GEMINI CONFIGURATION (Cloud API - Requires API Key)
# ============================================================================
# Get your API key: https://makersuite.google.com/app/apikey
# Uncomment and add your key if using AI_PROVIDER=gemini
# GEMINI_API_KEY=your_api_key_here

# ============================================================================
# REFERENCE TEXT CONFIGURATION (Optional - Advanced Users)
# ============================================================================
# Enable/disable scholarly reference texts
# Set to "true" or "false" (default: all true)

# Core lexicon (recommended)
ENABLE_THAYERS=true

# Additional scholarly texts
ENABLE_MOULTON_MILLIGAN=true
ENABLE_JOSEPHUS=true

# Verse commentaries (highly recommended)
ENABLE_ROBERTSON_WORD_PICTURES=true
ENABLE_VINCENT_WORD_STUDIES=true

# Grammar reference (currently quarantined due to OCR issues)
ENABLE_ROBERTSON_GRAMMAR=false
